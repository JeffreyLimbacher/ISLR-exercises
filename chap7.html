<!DOCTYPE html>
<html >

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>Jeffrey’s Answers to the ISLR Exercises</title>
  <meta name="description" content="This is a minimal example of using the bookdown package to write a book. The output format for this example is bookdown::gitbook.">
  <meta name="generator" content="bookdown 0.6.2 and GitBook 2.6.7">

  <meta property="og:title" content="Jeffrey’s Answers to the ISLR Exercises" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="This is a minimal example of using the bookdown package to write a book. The output format for this example is bookdown::gitbook." />
  <meta name="github-repo" content="rstudio/ISLR-exercises" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Jeffrey’s Answers to the ISLR Exercises" />
  
  <meta name="twitter:description" content="This is a minimal example of using the bookdown package to write a book. The output format for this example is bookdown::gitbook." />
  

<meta name="author" content="Jeffrey Limbacher">


<meta name="date" content="2018-01-31">

  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  
  
<link rel="prev" href="chap6.html">
<link rel="next" href="chap8.html">
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />









<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">A Minimal Book Example</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Introduction</a></li>
<li class="chapter" data-level="2" data-path="chap2.html"><a href="chap2.html"><i class="fa fa-check"></i><b>2</b> Statistical Learning</a></li>
<li class="chapter" data-level="3" data-path="chap3.html"><a href="chap3.html"><i class="fa fa-check"></i><b>3</b> Linear Regression</a></li>
<li class="chapter" data-level="4" data-path="chap4.html"><a href="chap4.html"><i class="fa fa-check"></i><b>4</b> Classification</a></li>
<li class="chapter" data-level="5" data-path="chap5.html"><a href="chap5.html"><i class="fa fa-check"></i><b>5</b> Resampling Methods</a></li>
<li class="chapter" data-level="6" data-path="chap6.html"><a href="chap6.html"><i class="fa fa-check"></i><b>6</b> Linear Model Selection and Regularization</a></li>
<li class="chapter" data-level="7" data-path="chap7.html"><a href="chap7.html"><i class="fa fa-check"></i><b>7</b> Moving Beyond Linearity</a></li>
<li class="chapter" data-level="8" data-path="chap8.html"><a href="chap8.html"><i class="fa fa-check"></i><b>8</b> Moving Beyond Linearity</a></li>
<li class="chapter" data-level="9" data-path="support-vector-machines.html"><a href="support-vector-machines.html"><i class="fa fa-check"></i><b>9</b> Support Vector Machines</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Jeffrey’s Answers to the ISLR Exercises</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="chap7" class="section level1">
<h1><span class="header-section-number">Chapter 7</span> Moving Beyond Linearity</h1>
<ol style="list-style-type: decimal">
<li><ol style="list-style-type: lower-alpha">
<li>Note that if we have <span class="math inline">\(x \leq \xi\)</span>, then <span class="math inline">\((x- \xi)^3_+= 0\)</span>, so <span class="math inline">\(f(x)\)</span> reduces to
<span class="math display">\[\begin{align}
f(x) &amp;= \beta_0 + \beta_1 x + \beta_2 x^2 + \beta_3 x^3 + \beta_4(x-\xi)^3_+ \\
&amp;= \beta_0 + \beta_1 x + \beta_2 x^2 + \beta_3 x^3\, .
\end{align}\]</span>
This gives coefficients <span class="math inline">\(a_1 = \beta_0\)</span>, <span class="math inline">\(b_1 = \beta_1\)</span>, <span class="math inline">\(c_1 = \beta_2\)</span>, <span class="math inline">\(d_1 = \beta_3\)</span>.</li>
<li>Remember that <span class="math inline">\((x-\xi)^3 = x^3 - 3x^2 \xi + 3x \xi^2 - \xi^3\)</span>. Then expanding <span class="math inline">\((x-\xi)^3_+\)</span> within <span class="math inline">\(f(x)\)</span> gives
<span class="math display" id="eq:expandedf">\[\begin{align}
f(x) &amp;= \beta_0 + \beta_1 x + \beta_2 x^2 + \beta_3 x^3 + \beta_4(x-\xi)^3_+ \nonumber \\
&amp;= \beta_0 + \beta_1 x + \beta_2 x^2 + \beta_3 x^3 + \beta_4(x^3 - 3x^2 \xi + 3x \xi^2 - \xi^3) \nonumber \\
&amp;= \beta_0 - \beta_4\xi^3 + (\beta_1+ 3 \beta_4 \xi^2)x + (\beta_2 - 3 \beta_4 \xi)x^2 + (\beta_3 + \beta_4) x^3 \, .
\tag{7.1}
\end{align}\]</span>
Equating <span class="math inline">\(f_2(x)\)</span> with <a href="chap7.html#eq:expandedf">(7.1)</a>, we get that <span class="math inline">\(a_2 = \beta_0 - \beta_4 \xi^3\)</span>, <span class="math inline">\(b_2 = \beta_1 + 3 \beta_4 \xi^3\)</span>, <span class="math inline">\(c_2 = \beta_2 - 3 \beta_4 \xi\)</span>, and <span class="math inline">\(d_4 = \beta_3 + \beta_4\)</span>.</li>
<li>Directly plugging into <span class="math inline">\(f_1(x)\)</span>,
<span class="math display">\[\begin{equation}
f_1(\xi) = \beta_0 + \beta_1 \xi + \beta_2 \xi^2 + \beta_3 \xi^3\, .
\end{equation}\]</span>
Plugging into <span class="math inline">\(f_2(x)\)</span>,
<span class="math display">\[\begin{align}
f_2(\xi) &amp;= \beta_0 - \beta_4 \xi^3 + (\beta_1 + 3\beta_4 \xi^2)\xi +(\beta_2 - 3 \beta_4 \xi)\xi^2 + (\beta_3 + \beta_4) \xi^3 \\
&amp;= \beta_0 - \beta_4 \xi^3 + \beta_1\xi + 3\beta_4\xi^3 + \beta_2\xi^2 - 3\beta_4\xi^3 + \beta_3 + \beta_4 \xi^3 \\
&amp;= \beta_0 - \beta_1 \xi + \beta_2 \xi^2 + \beta_3\xi^3\, .
\end{align}\]</span>
This gives us that <span class="math inline">\(f_1(\xi) = f_2(\xi)\)</span>.</li>
<li>First note that
<span class="math display">\[\begin{align}
f_1&#39;(x) &amp;= \beta_1+2\beta_2x + 3\beta_3x^2  \, ,\\
f_2&#39;(x) &amp;= \beta_1 + 3\beta_4\xi^2 + 2(\beta_2- 3\beta_4\xi)x + 3(\beta_3+\beta_4)x^2 \, .
\end{align}\]</span>
Plugging in <span class="math inline">\(\xi\)</span> into <span class="math inline">\(f_1&#39;(x)\)</span>,
<span class="math display">\[\begin{equation}
f_1&#39;(\xi) = \beta_1+2\beta_2 \xi + 3\beta_3 \xi^2
\end{equation}\]</span>
Plugging <span class="math inline">\(\xi\)</span> into <span class="math inline">\(f_2&#39;(x)\)</span>,
<span class="math display">\[\begin{align}
f_2&#39;(\xi) &amp;= \beta_1 + 3\beta_4\xi^2 + 2(\beta_2- 3\beta_4\xi)\xi + 3(\beta_3+\beta_4)\xi^2\\
&amp;= \beta_1 + 3 \beta_4 \xi^2 + 2\beta_2 \xi - 6\beta_4 \xi^2 + 3\beta_3\xi^2 + 3\beta_4\xi^2\\
&amp;= \beta_1 + 2\beta_2 \xi + 3\beta_3 \xi^2
\end{align}\]</span>
which is <span class="math inline">\(f_1&#39;(\xi)\)</span>.</li>
<li>We have
<span class="math display">\[\begin{align}
f_1&#39;&#39;(x) &amp;= 2\beta_2 + 6\beta_3 x \, , \\
f_2&#39;&#39;(x) &amp;= 2\beta_2 - 6\beta_4 \xi + (6\beta_3 + 6\beta_4) x \, .
\end{align}\]</span>
So,
<span class="math display">\[\begin{equation}
f_1&#39;&#39;(\xi) = 2\beta_2 + 6\beta_3 \xi \, .
\end{equation}\]</span>
And plugging <span class="math inline">\(\xi\)</span> into <span class="math inline">\(f_2&#39;&#39;(x)\)</span>, we have
<span class="math display">\[\begin{align}
f_2&#39;&#39;(\xi) &amp;= 2\beta_2 - 6\beta_4 \xi + (6\beta_3 + 6\beta_4) \xi \\
&amp;= 2 \beta_2 - 6\beta_4 \xi + 6 \beta_3 \xi + 6 \beta_4 \xi \\
&amp;= 2\beta_2 + 6\beta_3 \xi \, .
\end{align}\]</span>
This shows that <span class="math inline">\(f_1&#39;&#39;(\xi) = f_2&#39;&#39;(\xi)\)</span>.</li>
</ol></li>
<li>I’m not interested in sketching as much as describing the class of solutions and which solution is best within each one.
<ol style="list-style-type: lower-alpha">
<li>If <span class="math inline">\(m=0\)</span>, then we are saying then if <span class="math inline">\(g(x)&gt;0\)</span> at any point (ignoring issues of measure), then <span class="math inline">\(\lambda \int g(x)^2 dx \rightarrow \infty\)</span> as <span class="math inline">\(\lambda \rightarrow \infty\)</span>, so the only solution of <span class="math inline">\(\hat{g}\)</span> is <span class="math inline">\(\hat{g}(x) = 0\)</span>.</li>
<li>This must be a constant function since <span class="math inline">\(f&#39;(x) = 0\)</span> for any constant function <span class="math inline">\(f\)</span>. In this case, the solution that minimizes the error would be <span class="math inline">\(\hat{g}(x) = \bar{y}\)</span>.</li>
<li>In this case, it is a linear function since <span class="math inline">\(f&#39;&#39;(x) = 0\)</span> for any linear function. This reduces to the linear least squares solution.</li>
<li>This would be a quadratic solution linear least squares fit.</li>
<li>Since <span class="math inline">\(\lambda=0\)</span>, we would probably be the same in the case of <span class="math inline">\(\lambda=0\)</span> and <span class="math inline">\(m=2\)</span>, so we would get an interpolating spline.</li>
</ol></li>
<li></li>
</ol>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">x &lt;-<span class="st"> </span><span class="kw">seq</span>(<span class="op">-</span><span class="dv">2</span>,<span class="dv">2</span>,.<span class="dv">01</span>)
y &lt;-<span class="st"> </span><span class="dv">1</span> <span class="op">+</span><span class="st"> </span><span class="dv">1</span><span class="op">*</span>x <span class="op">+</span><span class="st"> </span>(x<span class="op">-</span><span class="dv">1</span>)<span class="op">^</span><span class="dv">2</span><span class="op">*</span>(x<span class="op">&gt;=</span><span class="dv">1</span>)
<span class="kw">plot</span>(x,y,<span class="dt">type=</span><span class="st">&quot;l&quot;</span>)</code></pre></div>
<p><img src="ISLR-exercises_files/figure-html/unnamed-chunk-172-1.png" width="672" /></p>
<ol start="4" style="list-style-type: decimal">
<li>Before we even plot, we can note that <span class="math inline">\(b_2\)</span> actually has no effect for <span class="math inline">\(x \in [-2,2]\)</span>.</li>
</ol>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">x &lt;-<span class="st"> </span><span class="kw">seq</span>(<span class="op">-</span><span class="dv">2</span>, <span class="dv">2</span>, .<span class="dv">01</span>)
b1 &lt;-<span class="st"> </span><span class="cf">function</span>(x) (x <span class="op">&gt;=</span><span class="st"> </span><span class="dv">0</span> <span class="op">&amp;</span><span class="st"> </span>x<span class="op">&lt;=</span><span class="dv">2</span>)<span class="op">-</span>(x<span class="op">-</span><span class="dv">1</span>)<span class="op">*</span>(x<span class="op">&gt;=</span><span class="dv">1</span> <span class="op">&amp;</span><span class="st"> </span>x<span class="op">&lt;=</span><span class="dv">2</span>)
b2 &lt;-<span class="st"> </span><span class="cf">function</span>(x) (x<span class="op">-</span><span class="dv">3</span>)<span class="op">*</span>(x<span class="op">&gt;=</span><span class="dv">3</span> <span class="op">&amp;</span><span class="st"> </span>x<span class="op">&lt;=</span><span class="dv">4</span>)<span class="op">+</span>(x<span class="op">&gt;</span><span class="dv">4</span> <span class="op">&amp;</span><span class="st"> </span>x<span class="op">&lt;=</span><span class="dv">5</span>)
y &lt;-<span class="st"> </span><span class="dv">1</span> <span class="op">+</span><span class="st"> </span><span class="kw">b1</span>(x) <span class="op">+</span><span class="st"> </span><span class="dv">3</span><span class="op">*</span><span class="kw">b2</span>(x)
<span class="kw">plot</span>(x,y,<span class="dt">type=</span><span class="st">&quot;l&quot;</span>)</code></pre></div>
<p><img src="ISLR-exercises_files/figure-html/unnamed-chunk-173-1.png" width="672" /></p>
<ol start="5" style="list-style-type: decimal">
<li><ol style="list-style-type: lower-alpha">
<li>As <span class="math inline">\(\lambda \rightarrow \infty\)</span>, <span class="math inline">\(\hat{g}_4\)</span> will have the smaller training RSS. That is because it is allowed to have more variability.</li>
<li>As <span class="math inline">\(\lambda \rightarrow \infty\)</span>, we cannot know if <span class="math inline">\(\hat{g}_1\)</span> or <span class="math inline">\(\hat{g}_2\)</span> will have lower test RSS. We do not know what the true response is, so it is possible it is a very high degree polynomial, in which case <span class="math inline">\(\hat{g}_2\)</span> will fit it better. However, if the true response is a line, then <span class="math inline">\(\hat{g}_1\)</span> will have a better test RSS.</li>
<li>For <span class="math inline">\(\lambda=0\)</span>, the two models degenerate into the same model, so they will have the same training and test RSS.</li>
</ol></li>
<li></li>
</ol>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">data</span>(Wage,<span class="dt">package=</span><span class="st">&quot;ISLR&quot;</span>)
<span class="kw">head</span>(Wage)</code></pre></div>
<pre><code>##        year age           maritl     race       education
## 231655 2006  18 1. Never Married 1. White    1. &lt; HS Grad
## 86582  2004  24 1. Never Married 1. White 4. College Grad
## 161300 2003  45       2. Married 1. White 3. Some College
## 155159 2003  43       2. Married 3. Asian 4. College Grad
## 11443  2005  50      4. Divorced 1. White      2. HS Grad
## 376662 2008  54       2. Married 1. White 4. College Grad
##                    region       jobclass         health health_ins
## 231655 2. Middle Atlantic  1. Industrial      1. &lt;=Good      2. No
## 86582  2. Middle Atlantic 2. Information 2. &gt;=Very Good      2. No
## 161300 2. Middle Atlantic  1. Industrial      1. &lt;=Good     1. Yes
## 155159 2. Middle Atlantic 2. Information 2. &gt;=Very Good     1. Yes
## 11443  2. Middle Atlantic 2. Information      1. &lt;=Good     1. Yes
## 376662 2. Middle Atlantic 2. Information 2. &gt;=Very Good     1. Yes
##         logwage      wage
## 231655 4.318063  75.04315
## 86582  4.255273  70.47602
## 161300 4.875061 130.98218
## 155159 5.041393 154.68529
## 11443  4.318063  75.04315
## 376662 4.845098 127.11574</code></pre>
<pre><code>a.

```r
library(boot)
set.seed(1)
cv.errors &lt;- double(10)
for(i in 1:10) {
  glm.fit &lt;- glm(wage ~ poly(age,i), data=Wage)
  cv.errors[i] &lt;- cv.glm(Wage, glm.fit, K=10)$delta[1]
}
plot(cv.errors,type=&quot;l&quot;,xlab=&quot;degree&quot;,ylab=&quot;error&quot;)
abline(v=which.min(cv.errors),col=&quot;red&quot;,lty=2)
```

&lt;img src=&quot;ISLR-exercises_files/figure-html/unnamed-chunk-175-1.png&quot; width=&quot;672&quot; /&gt;
A polynomial of degree 4 is the best fit to the data.

```r
lm.mods&lt;-list()
for(i in 1:10) {
  lm.fit &lt;- lm(wage ~ poly(age,i),data=Wage)
  lm.mods[[i]] &lt;- lm.fit
}
do.call(&quot;anova&quot;,lm.mods)
```

```
## Analysis of Variance Table
## 
## Model  1: wage ~ poly(age, i)
## Model  2: wage ~ poly(age, i)
## Model  3: wage ~ poly(age, i)
## Model  4: wage ~ poly(age, i)
## Model  5: wage ~ poly(age, i)
## Model  6: wage ~ poly(age, i)
## Model  7: wage ~ poly(age, i)
## Model  8: wage ~ poly(age, i)
## Model  9: wage ~ poly(age, i)
## Model 10: wage ~ poly(age, i)
##    Res.Df     RSS Df Sum of Sq        F    Pr(&gt;F)    
## 1    2998 5022216                                    
## 2    2997 4793430  1    228786 143.7638 &lt; 2.2e-16 ***
## 3    2996 4777674  1     15756   9.9005  0.001669 ** 
## 4    2995 4771604  1      6070   3.8143  0.050909 .  
## 5    2994 4770322  1      1283   0.8059  0.369398    
## 6    2993 4766389  1      3932   2.4709  0.116074    
## 7    2992 4763834  1      2555   1.6057  0.205199    
## 8    2991 4763707  1       127   0.0796  0.777865    
## 9    2990 4756703  1      7004   4.4014  0.035994 *  
## 10   2989 4756701  1         3   0.0017  0.967529    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
```
From the analysis of variance, we can see that the stops being significant at the 4th degree polynomial. This agrees with the cross-validaiton results.
A plot of the polynomial fit is below.

```r
plot(Wage$age,Wage$wage,xlab=&quot;age&quot;,ylab=&quot;wage&quot;)
lines(predict(lm.mods[[i]],list(age=seq(from=min(Wage$age),to=max(Wage$age),length.out=100))),col=&quot;red&quot;)
legend(&quot;topright&quot;,c(&quot;data&quot;,&quot;fit&quot;),pch=c(1,NA),lty=c(NA,1),col=c(&quot;black&quot;,&quot;red&quot;))
```

&lt;img src=&quot;ISLR-exercises_files/figure-html/unnamed-chunk-177-1.png&quot; width=&quot;672&quot; /&gt;
b.

```r
set.seed(1)
cv.errors &lt;- double(10)
for(i in 1:10) {
  n_ints &lt;- i+2
  k_folds &lt;- 10 
  folds &lt;- cut(seq(1,nrow(Wage)),breaks=k_folds,labels=FALSE)
  errors &lt;- double(k_folds)
  breaks &lt;- quantile(Wage$age,p=seq(0,1,by=1/n_ints))
  Wage$age.cut &lt;- cut(Wage$age,breaks=n_ints)
  for(k in 1:k_folds){
    train &lt;- folds != k
    glm.fit &lt;- lm(wage ~ age.cut, data=Wage, subset=train)
    y.pred &lt;- predict(glm.fit,Wage[!train,])
    errors[k] &lt;- mean((y.pred-Wage$wage[!train])^2)
  }
  cv.errors[i] &lt;-mean(errors)
}
plot(3:12,cv.errors,type=&quot;l&quot;,xlab=&quot;number of intervals&quot;)
abline(v=which.min(cv.errors)+2,col=&quot;red&quot;,lty=2)
```

&lt;img src=&quot;ISLR-exercises_files/figure-html/unnamed-chunk-178-1.png&quot; width=&quot;672&quot; /&gt;
A plot of the model is below.

```r
plot(Wage$age,Wage$wage,xlab=&quot;age&quot;,ylab=&quot;wage&quot;)
lm.fit &lt;- lm(wage ~ cut(age,breaks=8), data=Wage)
age.grid &lt;- seq(min(Wage$age),max(Wage$age))
y.pred&lt;-predict(lm.fit,list(age=age.grid))
lines(age.grid,y.pred,col=&quot;red&quot;)
legend(&quot;topright&quot;,c(&quot;data&quot;,&quot;fit&quot;),pch=c(1,NA),lty=c(NA,1),col=c(&quot;black&quot;,&quot;red&quot;))
```

&lt;img src=&quot;ISLR-exercises_files/figure-html/unnamed-chunk-179-1.png&quot; width=&quot;672&quot; /&gt;</code></pre>
<ol start="8" style="list-style-type: decimal">
<li></li>
</ol>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">data</span>(Auto,<span class="dt">package=</span><span class="st">&quot;ISLR&quot;</span>)
<span class="kw">head</span>(Auto)</code></pre></div>
<pre><code>##   mpg cylinders displacement horsepower weight acceleration year origin
## 1  18         8          307        130   3504         12.0   70      1
## 2  15         8          350        165   3693         11.5   70      1
## 3  18         8          318        150   3436         11.0   70      1
## 4  16         8          304        150   3433         12.0   70      1
## 5  17         8          302        140   3449         10.5   70      1
## 6  15         8          429        198   4341         10.0   70      1
##                        name
## 1 chevrolet chevelle malibu
## 2         buick skylark 320
## 3        plymouth satellite
## 4             amc rebel sst
## 5               ford torino
## 6          ford galaxie 500</code></pre>
<p>We will find the relationship between horsepower, weight, and mpgs.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(splines)
<span class="kw">set.seed</span>(<span class="dv">1</span>)
wgt.cv.errs &lt;-<span class="st"> </span><span class="kw">double</span>(<span class="dv">20</span>)
<span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span><span class="dv">20</span>){
  folds &lt;-<span class="st"> </span><span class="kw">cut</span>(<span class="kw">seq</span>(<span class="dv">1</span>,<span class="kw">nrow</span>(Auto)),<span class="dt">breaks=</span>k_folds,<span class="dt">labels=</span><span class="ot">FALSE</span>)
  errors &lt;-<span class="st"> </span><span class="kw">double</span>(<span class="dv">10</span>)
  <span class="cf">for</span>(k <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span><span class="dv">10</span>) {
    train &lt;-<span class="st"> </span>folds <span class="op">!=</span><span class="st"> </span>k
    mod&lt;-<span class="kw">lm</span>(mpg <span class="op">~</span><span class="st"> </span><span class="kw">ns</span>(weight,<span class="dt">df=</span>i),<span class="dt">data=</span>Auto,<span class="dt">subset=</span>train)
    y.pred&lt;-<span class="kw">predict</span>(mod,Auto[<span class="op">!</span>train,])
    errors[k]&lt;-<span class="kw">mean</span>((y.pred<span class="op">-</span>Auto<span class="op">$</span>mpg[<span class="op">!</span>train])<span class="op">^</span><span class="dv">2</span>)
  }
  wgt.cv.errs[i] &lt;-<span class="st"> </span><span class="kw">mean</span>(errors)
}
<span class="kw">plot</span>(<span class="dv">1</span><span class="op">:</span><span class="kw">length</span>(wgt.cv.errs),wgt.cv.errs,<span class="dt">xlab=</span><span class="st">&quot;DF&quot;</span>,<span class="dt">ylab=</span><span class="st">&quot;Cross validation error&quot;</span>,<span class="dt">type=</span><span class="st">&quot;l&quot;</span>)
<span class="kw">abline</span>(<span class="dt">v=</span><span class="kw">which.min</span>(wgt.cv.errs),<span class="dt">lty=</span><span class="dv">2</span>,<span class="dt">col=</span><span class="st">&quot;red&quot;</span>)</code></pre></div>
<p><img src="ISLR-exercises_files/figure-html/unnamed-chunk-181-1.png" width="672" /> Although 8 is the minimum, 2 appears just as good in addition to being simpler.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">mod &lt;-<span class="st"> </span><span class="kw">lm</span>(mpg <span class="op">~</span><span class="st"> </span><span class="kw">ns</span>(weight,<span class="dt">df=</span><span class="dv">2</span>),<span class="dt">data=</span>Auto)
wgt.grid =<span class="st"> </span><span class="kw">seq</span>(<span class="kw">min</span>(Auto<span class="op">$</span>weight),<span class="kw">max</span>(Auto<span class="op">$</span>weight),<span class="dt">by=</span><span class="dv">1</span>)
mpg.pred&lt;-<span class="kw">predict</span>(mod,<span class="kw">list</span>(<span class="dt">weight=</span>wgt.grid))
<span class="kw">plot</span>(Auto<span class="op">$</span>weight,Auto<span class="op">$</span>mpg,<span class="dt">xlab=</span><span class="st">&quot;weight&quot;</span>,<span class="dt">ylab=</span><span class="st">&quot;mpg&quot;</span>)
<span class="kw">lines</span>(wgt.grid,mpg.pred,<span class="dt">col=</span><span class="st">&quot;red&quot;</span>)</code></pre></div>
<p><img src="ISLR-exercises_files/figure-html/unnamed-chunk-182-1.png" width="672" /></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(splines)
<span class="kw">set.seed</span>(<span class="dv">1</span>)
fit &lt;-<span class="st"> </span><span class="kw">smooth.spline</span>(Auto<span class="op">$</span>horsepower,Auto<span class="op">$</span>mpg,<span class="dt">cv=</span><span class="ot">TRUE</span>)</code></pre></div>
<pre><code>## Warning in smooth.spline(Auto$horsepower, Auto$mpg, cv = TRUE): cross-
## validation with non-unique &#39;x&#39; values seems doubtful</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">plot</span>(fit,<span class="dt">type=</span><span class="st">&quot;l&quot;</span>,<span class="dt">col=</span><span class="st">&quot;red&quot;</span>)
<span class="kw">points</span>(Auto<span class="op">$</span>horsepower,Auto<span class="op">$</span>mpg)</code></pre></div>
<p><img src="ISLR-exercises_files/figure-html/unnamed-chunk-183-1.png" width="672" /> Now try with a GAM, but use ANOVA to see if we are adding anything by using the smoothing spline with the natural spline.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(gam)</code></pre></div>
<pre><code>## Loaded gam 1.14-4</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">gam.m1 &lt;-<span class="st"> </span><span class="kw">gam</span>(mpg <span class="op">~</span><span class="st"> </span><span class="kw">ns</span>(weight,<span class="dv">2</span>),<span class="dt">data=</span>Auto)
gam.m2 &lt;-<span class="st"> </span><span class="kw">gam</span>(mpg <span class="op">~</span><span class="st"> </span><span class="kw">ns</span>(weight,<span class="dv">2</span>) <span class="op">+</span><span class="st"> </span><span class="kw">s</span>(horsepower,fit<span class="op">$</span>lambda), <span class="dt">data=</span>Auto)
<span class="kw">anova</span>(gam.m1,gam.m2)</code></pre></div>
<pre><code>## Analysis of Deviance Table
## 
## Model 1: mpg ~ ns(weight, 2)
## Model 2: mpg ~ ns(weight, 2) + s(horsepower, fit$lambda)
##   Resid. Df Resid. Dev Df Deviance  Pr(&gt;Chi)    
## 1       389     6781.1                          
## 2       388     6244.6  1   536.52 7.754e-09 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<ol start="9" style="list-style-type: decimal">
<li></li>
</ol>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">data</span>(Boston,<span class="dt">package=</span><span class="st">&quot;MASS&quot;</span>)
<span class="kw">head</span>(Boston)</code></pre></div>
<pre><code>##      crim zn indus chas   nox    rm  age    dis rad tax ptratio  black
## 1 0.00632 18  2.31    0 0.538 6.575 65.2 4.0900   1 296    15.3 396.90
## 2 0.02731  0  7.07    0 0.469 6.421 78.9 4.9671   2 242    17.8 396.90
## 3 0.02729  0  7.07    0 0.469 7.185 61.1 4.9671   2 242    17.8 392.83
## 4 0.03237  0  2.18    0 0.458 6.998 45.8 6.0622   3 222    18.7 394.63
## 5 0.06905  0  2.18    0 0.458 7.147 54.2 6.0622   3 222    18.7 396.90
## 6 0.02985  0  2.18    0 0.458 6.430 58.7 6.0622   3 222    18.7 394.12
##   lstat medv
## 1  4.98 24.0
## 2  9.14 21.6
## 3  4.03 34.7
## 4  2.94 33.4
## 5  5.33 36.2
## 6  5.21 28.7</code></pre>
<pre><code>a. 

```r
poly.fit &lt;- lm(nox ~ poly(dis,degree=3), data=Boston)
summary(poly.fit)
```

```
## 
## Call:
## lm(formula = nox ~ poly(dis, degree = 3), data = Boston)
## 
## Residuals:
##       Min        1Q    Median        3Q       Max 
## -0.121130 -0.040619 -0.009738  0.023385  0.194904 
## 
## Coefficients:
##                         Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)             0.554695   0.002759 201.021  &lt; 2e-16 ***
## poly(dis, degree = 3)1 -2.003096   0.062071 -32.271  &lt; 2e-16 ***
## poly(dis, degree = 3)2  0.856330   0.062071  13.796  &lt; 2e-16 ***
## poly(dis, degree = 3)3 -0.318049   0.062071  -5.124 4.27e-07 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 0.06207 on 502 degrees of freedom
## Multiple R-squared:  0.7148, Adjusted R-squared:  0.7131 
## F-statistic: 419.3 on 3 and 502 DF,  p-value: &lt; 2.2e-16
```
Plotting the resulting regression:

```r
dis.grid &lt;- with(Boston, seq(min(dis), max(dis), by=(max(dis)-min(dis))/1000))
y.pred &lt;- predict(poly.fit,list(dis=dis.grid))
with(Boston, plot(dis,nox))
lines(dis.grid, y.pred, type=&quot;l&quot;, col=&quot;red&quot;)
```

&lt;img src=&quot;ISLR-exercises_files/figure-html/unnamed-chunk-187-1.png&quot; width=&quot;672&quot; /&gt;

b. Note that we expect the RSS to drop for every higher degree of polynomial here because we will fit to the model better with least squares.

```r
rss &lt;- double(10)
for(i in 1:10){
  poly.fit &lt;- lm(nox ~ poly(dis,degree=i), data=Boston)
  poly.sum &lt;- summary(poly.fit)
  rss[i] &lt;- sum(poly.sum$residuals^2)
}
data.frame(degree=1:10, rss)
```

```
##    degree      rss
## 1       1 2.768563
## 2       2 2.035262
## 3       3 1.934107
## 4       4 1.932981
## 5       5 1.915290
## 6       6 1.878257
## 7       7 1.849484
## 8       8 1.835630
## 9       9 1.833331
## 10     10 1.832171
```

c.

```r
set.seed(1)
cv.errs &lt;- double(10)
for(i in 1:10){
  k.folds &lt;- 10
  folds &lt;- rep(1:k_folds,length.out = nrow(Boston))
  errors &lt;- double(10)
  for(k in 1:10) {
    train &lt;- folds != k
    mod&lt;-lm(nox ~ poly(dis,degree=i),data=Boston,subset=train)
    y.pred&lt;-predict(mod,Boston[!train,])
    errors[k]&lt;-mean((y.pred-Boston$nox[!train])^2)
  }
  cv.errs[i] &lt;- mean(errors)
}
plot(1:10,cv.errs,xlab=&quot;degree&quot;,ylab=&quot;CV error&quot;,type=&quot;l&quot;)
abline(v=which.min(cv.errs),col=&quot;red&quot;,lty=2)
```

&lt;img src=&quot;ISLR-exercises_files/figure-html/unnamed-chunk-189-1.png&quot; width=&quot;672&quot; /&gt;
The cross-validation suggests that a 3rd degree polynomial gives the best results, but the 2nd degree could also be used for more simplicity.

d. 

```r
library(splines)
bs.fit &lt;- lm(nox ~ bs(dis,df=4), data=Boston)
y.pred &lt;- predict(bs.fit, list(dis=dis.grid))
with(Boston,plot(dis,nox))
lines(dis.grid, y.pred, type=&quot;l&quot;, col=&quot;red&quot;)
```

&lt;img src=&quot;ISLR-exercises_files/figure-html/unnamed-chunk-190-1.png&quot; width=&quot;672&quot; /&gt;
I let `bs` choose the knot for me. `bs` chooses the median in this case.

e. We expect it to be lower again since we are fitting a more flexible model to the data.

```r
dfs &lt;- c(3, 4, 5, 7, 10, 15, 25, 50)
rss &lt;- double(length(dfs))
for(i in seq_along(dfs)){
  df &lt;- dfs[i]
  bs.fit &lt;- lm(nox ~ bs(dis,df=df), data=Boston)
  y.pred &lt;- predict(bs.fit)
  rss[i] &lt;- sum((y.pred-Boston$nox)^2)
}
data.frame(df=dfs,rss)
```

```
##   df      rss
## 1  3 1.934107
## 2  4 1.922775
## 3  5 1.840173
## 4  7 1.829884
## 5 10 1.792535
## 6 15 1.782798
## 7 25 1.769957
## 8 50 1.679047
```

f.

```r
set.seed(927)
dfs &lt;- 3:50
cv.errs &lt;- double(length(dfs))
for(i in seq_along(dfs)) {
  df &lt;- dfs[i]
  k.folds &lt;- 10
  folds &lt;- rep(1:k_folds,length.out = nrow(Boston))
  errors &lt;- double(10)
  for(k in 1:10) {
    train &lt;- folds != k
    mod&lt;-lm(nox ~ bs(dis,df=df),data=Boston,subset=train)
    y.pred&lt;-predict(mod,Boston[!train,])
    errors[k]&lt;-mean((y.pred-Boston$nox[!train])^2)
  }
  cv.errs[i] &lt;- mean(errors)
}
plot(dfs,cv.errs,type=&quot;l&quot;)
abline(v=dfs[which.min(cv.errs)],lty=2,col=&quot;red&quot;)
```

&lt;img src=&quot;ISLR-exercises_files/figure-html/unnamed-chunk-192-1.png&quot; width=&quot;672&quot; /&gt;
The minimum occurs at 12. A plot of it is below.

```r
best.bs.fit &lt;- lm(nox ~ bs(dis,df=dfs[which.min(cv.errs)]), data=Boston)
y.pred &lt;- predict(best.bs.fit, list(dis=dis.grid))
with(Boston,plot(dis,nox))
lines(dis.grid,y.pred,col=&quot;red&quot;)
```

&lt;img src=&quot;ISLR-exercises_files/figure-html/unnamed-chunk-193-1.png&quot; width=&quot;672&quot; /&gt;
That kind of looks like overfitting. It appears that a df of 5 also gives comparable results while retaining much more accuracy. 

```r
bs.5.fit &lt;- lm(nox ~ bs(dis,df=5), data=Boston)
y.pred &lt;- predict(bs.5.fit, list(dis=dis.grid))
with(Boston,plot(dis,nox))
lines(dis.grid,y.pred,col=&quot;red&quot;)
```

&lt;img src=&quot;ISLR-exercises_files/figure-html/unnamed-chunk-194-1.png&quot; width=&quot;672&quot; /&gt;</code></pre>
<ol start="10" style="list-style-type: decimal">
<li><ol style="list-style-type: lower-alpha">
<li></li>
<li>Let’s visualize these relationships before choosing how we want to model these.</li>
</ol>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(gam)
sig.vars &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;Private&quot;</span>, <span class="st">&quot;Accept&quot;</span>, <span class="st">&quot;Enroll&quot;</span>, <span class="st">&quot;Room.Board&quot;</span>,<span class="st">&quot;Terminal&quot;</span>, <span class="st">&quot;perc.alumni&quot;</span>, <span class="st">&quot;Expend&quot;</span>, <span class="st">&quot;Grad.Rate&quot;</span>)
<span class="kw">par</span>(<span class="dt">mfcol=</span><span class="kw">c</span>(<span class="dv">3</span>,<span class="dv">3</span>))
<span class="cf">for</span>( v <span class="cf">in</span> sig.vars){
  <span class="kw">plot</span>(College[train,v],College[train,<span class="st">&quot;Outstate&quot;</span>],<span class="dt">xlab=</span>v,<span class="dt">ylab=</span><span class="st">&quot;Outstate&quot;</span>)
}</code></pre></div>
<p><img src="ISLR-exercises_files/figure-html/unnamed-chunk-196-1.png" width="672" /> Now build a gam. I really have no intuition for how to select which ones. I suppose there must be a lot of cross-validation, then comparing which cross-validation worked best for each technique.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">gam.mod &lt;-<span class="st"> </span><span class="kw">gam</span>(Outstate <span class="op">~</span><span class="st"> </span>Private <span class="op">+</span><span class="st"> </span><span class="kw">s</span>(Room.Board) <span class="op">+</span><span class="st"> </span><span class="kw">lo</span>(Expend,<span class="dt">span=</span>.<span class="dv">1</span>) <span class="op">+</span><span class="st"> </span><span class="kw">lo</span>(Accept,<span class="dt">span=</span>.<span class="dv">1</span>) <span class="op">+</span><span class="st"> </span><span class="kw">s</span>(Terminal,<span class="dt">df=</span><span class="dv">10</span>) <span class="op">+</span><span class="st"> </span><span class="kw">bs</span>(Grad.Rate, <span class="dt">df=</span><span class="dv">4</span>) <span class="op">+</span><span class="st"> </span><span class="kw">lo</span>(Enroll,<span class="dt">span=</span>.<span class="dv">1</span>) <span class="op">+</span><span class="st"> </span><span class="kw">ns</span>(perc.alumni,<span class="dt">df=</span><span class="dv">6</span>), <span class="dt">data=</span>College, <span class="dt">subset=</span>train)</code></pre></div>
<pre><code>## Warning in general.wam(x, z, wz, fit$smooth, which, fit$smooth.frame,
## bf.maxit, : general.wam convergence not obtained in 30 iterations

## Warning in general.wam(x, z, wz, fit$smooth, which, fit$smooth.frame,
## bf.maxit, : general.wam convergence not obtained in 30 iterations

## Warning in general.wam(x, z, wz, fit$smooth, which, fit$smooth.frame,
## bf.maxit, : general.wam convergence not obtained in 30 iterations</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">par</span>(<span class="dt">mfcol=</span><span class="kw">c</span>(<span class="dv">3</span>,<span class="dv">3</span>))
<span class="kw">plot</span>(gam.mod)</code></pre></div>
<img src="ISLR-exercises_files/figure-html/unnamed-chunk-197-1.png" width="672" />
<ol start="3" style="list-style-type: lower-alpha">
<li></li>
</ol>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">gam.pred &lt;-<span class="st"> </span><span class="kw">predict</span>(gam.mod, College[<span class="op">-</span>train,])</code></pre></div>
<pre><code>## Warning in gam.lo(data[[&quot;lo(Expend, span = 0.1)&quot;]], z, w, span = 0.1,
## degree = 1, : eval 56233</code></pre>
<pre><code>## Warning in gam.lo(data[[&quot;lo(Expend, span = 0.1)&quot;]], z, w, span = 0.1,
## degree = 1, : upperlimit 45915</code></pre>
<pre><code>## Warning in gam.lo(data[[&quot;lo(Expend, span = 0.1)&quot;]], z, w, span = 0.1,
## degree = 1, : extrapolation not allowed with blending</code></pre>
<pre><code>## Warning in gam.lo(data[[&quot;lo(Accept, span = 0.1)&quot;]], z, w, span = 0.1,
## degree = 1, : eval 26330</code></pre>
<pre><code>## Warning in gam.lo(data[[&quot;lo(Accept, span = 0.1)&quot;]], z, w, span = 0.1,
## degree = 1, : upperlimit 18837</code></pre>
<pre><code>## Warning in gam.lo(data[[&quot;lo(Accept, span = 0.1)&quot;]], z, w, span = 0.1,
## degree = 1, : extrapolation not allowed with blending</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">lm.mod &lt;-<span class="st"> </span><span class="kw">lm</span>(<span class="kw">as.formula</span>(<span class="kw">paste</span>(<span class="kw">c</span>(<span class="st">&quot;Outstate ~ &quot;</span>, sig.vars),<span class="st">&quot;+&quot;</span>,<span class="ot">TRUE</span>)),<span class="dt">data=</span>College, <span class="dt">subset=</span>train)
lm.pred &lt;-<span class="st"> </span><span class="kw">predict</span>(lm.mod, College[<span class="op">-</span>train,])
<span class="kw">mean</span>((gam.pred<span class="op">-</span>College[<span class="op">-</span>train,<span class="st">&quot;Outstate&quot;</span>])<span class="op">^</span><span class="dv">2</span>)</code></pre></div>
<pre><code>## [1] 3679466</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">mean</span>((lm.pred<span class="op">-</span>College[<span class="op">-</span>train,<span class="st">&quot;Outstate&quot;</span>])<span class="op">^</span><span class="dv">2</span>)</code></pre></div>
<pre><code>## [1] 15574088</code></pre>
In either case, our model performs better than the linear model.
<ol start="4" style="list-style-type: lower-alpha">
<li>Terminal, Grad.Rate, and Expend seem to be non-linear.</li>
</ol></li>
<li><ol style="list-style-type: lower-alpha">
<li></li>
</ol>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">set.seed</span>(<span class="dv">927</span>)
x1 &lt;-<span class="st"> </span><span class="kw">rnorm</span>(<span class="dv">100</span>,<span class="dv">20</span>,<span class="dv">5</span>)
x2 &lt;-<span class="st"> </span><span class="kw">rnorm</span>(<span class="dv">100</span>,<span class="dv">10</span>,<span class="dv">5</span>)
y &lt;-<span class="st"> </span><span class="dv">3</span> <span class="op">+</span><span class="st"> </span><span class="dv">2</span><span class="op">*</span>x1 <span class="op">+</span><span class="st"> </span>x2 <span class="op">+</span><span class="st"> </span><span class="kw">rnorm</span>(<span class="dv">100</span>)</code></pre></div>
<ol start="2" style="list-style-type: lower-alpha">
<li></li>
</ol>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">b1 &lt;-<span class="st"> </span><span class="op">-</span><span class="dv">1</span></code></pre></div>
<ol start="3" style="list-style-type: lower-alpha">
<li></li>
</ol>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">a &lt;-<span class="st"> </span>y<span class="op">-</span>b1<span class="op">*</span>x1
b2 &lt;-<span class="st"> </span><span class="kw">lm</span>(a<span class="op">~</span>x2)<span class="op">$</span>coef[<span class="dv">2</span>]</code></pre></div>
<ol start="4" style="list-style-type: lower-alpha">
<li></li>
</ol>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">a &lt;-<span class="st"> </span>y<span class="op">-</span>b2<span class="op">*</span>x2
b1 &lt;-<span class="st"> </span><span class="kw">lm</span>(a<span class="op">~</span>x1)<span class="op">$</span>coef[<span class="dv">2</span>]</code></pre></div>
<ol start="5" style="list-style-type: lower-alpha">
<li>It converges very quickly, so I only plot the first 10 or so.</li>
</ol>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">n&lt;-<span class="dv">10</span>
b0s &lt;-<span class="st"> </span><span class="kw">double</span>(n)
b1s &lt;-<span class="st"> </span><span class="kw">double</span>(n)
b2s &lt;-<span class="st"> </span><span class="kw">double</span>(n)
b0s[<span class="dv">1</span>] &lt;-<span class="st"> </span><span class="kw">mean</span>(y <span class="op">-</span><span class="st"> </span>b1<span class="op">*</span>x1 <span class="op">-</span><span class="st"> </span>b2<span class="op">*</span>x2)
b1s[<span class="dv">1</span>] &lt;-<span class="st"> </span>b1
b2s[<span class="dv">1</span>] &lt;-<span class="st"> </span>b2
<span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">2</span><span class="op">:</span>n){
  a &lt;-<span class="st"> </span>y<span class="op">-</span>b1<span class="op">*</span>x1
  b2 &lt;-<span class="st"> </span><span class="kw">lm</span>(a<span class="op">~</span>x2)<span class="op">$</span>coef[<span class="dv">2</span>]
  a &lt;-<span class="st"> </span>y<span class="op">-</span>b2<span class="op">*</span>x2
  b1 &lt;-<span class="st"> </span><span class="kw">lm</span>(a<span class="op">~</span>x1)<span class="op">$</span>coef[<span class="dv">2</span>]
  b0 &lt;-<span class="st"> </span><span class="kw">mean</span>(y <span class="op">-</span><span class="st"> </span>b1<span class="op">*</span>x1 <span class="op">-</span><span class="st"> </span>b2<span class="op">*</span>x2)
  b0s[i] &lt;-<span class="st"> </span>b0
  b1s[i] &lt;-<span class="st"> </span>b1
  b2s[i] &lt;-<span class="st"> </span>b2
}
<span class="kw">matplot</span>(<span class="dt">x=</span><span class="dv">1</span><span class="op">:</span>n,<span class="dt">y=</span><span class="kw">cbind</span>(b0s,b1s,b2s),<span class="dt">type=</span><span class="st">&quot;l&quot;</span>,<span class="dt">lty=</span><span class="kw">c</span>(<span class="dv">2</span>,<span class="dv">2</span>,<span class="dv">2</span>))
<span class="kw">legend</span>(<span class="dt">x=</span><span class="st">&quot;topright&quot;</span>,<span class="kw">c</span>(<span class="st">&quot;beta_0&quot;</span>,<span class="st">&quot;beta_1&quot;</span>,<span class="st">&quot;beta_2&quot;</span>),<span class="dt">lty=</span><span class="kw">c</span>(<span class="dv">2</span>,<span class="dv">2</span>,<span class="dv">2</span>),<span class="dt">col=</span><span class="kw">c</span>(<span class="dv">1</span>,<span class="dv">2</span>,<span class="dv">3</span>))</code></pre></div>
<img src="ISLR-exercises_files/figure-html/unnamed-chunk-203-1.png" width="672" />
<ol start="6" style="list-style-type: lower-alpha">
<li></li>
</ol>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">y.lm &lt;-<span class="st"> </span><span class="kw">lm</span>(y <span class="op">~</span><span class="st"> </span>x1 <span class="op">+</span><span class="st"> </span>x2)
<span class="kw">matplot</span>(<span class="dt">x=</span><span class="dv">1</span><span class="op">:</span>n,<span class="dt">y=</span><span class="kw">cbind</span>(b0s,b1s,b2s),<span class="dt">type=</span><span class="st">&quot;l&quot;</span>,<span class="dt">lty=</span><span class="kw">c</span>(<span class="dv">2</span>,<span class="dv">2</span>,<span class="dv">2</span>))
<span class="kw">legend</span>(<span class="dt">x=</span><span class="st">&quot;topright&quot;</span>,<span class="kw">c</span>(<span class="st">&quot;beta_0&quot;</span>,<span class="st">&quot;beta_1&quot;</span>,<span class="st">&quot;beta_2&quot;</span>),<span class="dt">lty=</span><span class="kw">c</span>(<span class="dv">2</span>,<span class="dv">2</span>,<span class="dv">2</span>),<span class="dt">col=</span><span class="kw">c</span>(<span class="dv">1</span>,<span class="dv">2</span>,<span class="dv">3</span>))
<span class="kw">abline</span>(<span class="dt">h=</span>y.lm<span class="op">$</span>coef[<span class="dv">1</span>],<span class="dt">lty=</span><span class="dv">1</span>,<span class="dt">col=</span><span class="st">&quot;black&quot;</span>)
<span class="kw">abline</span>(<span class="dt">h=</span>y.lm<span class="op">$</span>coef[<span class="dv">2</span>],<span class="dt">lty=</span><span class="dv">1</span>,<span class="dt">col=</span><span class="st">&quot;red&quot;</span>)
<span class="kw">abline</span>(<span class="dt">h=</span>y.lm<span class="op">$</span>coef[<span class="dv">3</span>],<span class="dt">lty=</span><span class="dv">1</span>,<span class="dt">col=</span><span class="st">&quot;green&quot;</span>)</code></pre></div>
<img src="ISLR-exercises_files/figure-html/unnamed-chunk-204-1.png" width="672" /></li>
<li></li>
</ol>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">p &lt;-<span class="st"> </span><span class="dv">100</span>
n&lt;-<span class="st"> </span><span class="dv">1000</span>
iters &lt;-<span class="st"> </span><span class="dv">25</span>
B &lt;-<span class="st"> </span><span class="kw">sample</span>(<span class="op">-</span><span class="dv">5</span><span class="op">:</span><span class="dv">5</span>,p,<span class="dt">replace=</span><span class="ot">TRUE</span>) <span class="co">#true coefficients</span>
Bs &lt;-<span class="st"> </span><span class="kw">matrix</span>(<span class="dt">nrow=</span>iters,<span class="dt">ncol=</span>p) <span class="co">#Store the coefficient estimates here for each iteration</span>
Bs[<span class="dv">1</span>,] &lt;-<span class="st"> </span><span class="kw">rep</span>(<span class="op">-</span><span class="dv">10</span>,p) <span class="co">#First guess is -100 for each coefficient</span>
X &lt;-<span class="st"> </span><span class="kw">rnorm</span>(p<span class="op">*</span>n)
<span class="kw">dim</span>(X) &lt;-<span class="st"> </span><span class="kw">c</span>(n,p)
y &lt;-<span class="st"> </span>X<span class="op">%*%</span>B  <span class="co">#add noise</span>
<span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span>(iters<span class="op">-</span><span class="dv">1</span>)){
  <span class="cf">for</span>(j <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span>p){
    a &lt;-<span class="st"> </span>y<span class="op">-</span>X[,<span class="op">-</span>j]<span class="op">%*%</span><span class="kw">as.matrix</span>(Bs[i,<span class="op">-</span>j]) <span class="co">#remove all but the jth estimate</span>
    Bs[i<span class="op">+</span><span class="dv">1</span>,j] &lt;-<span class="st"> </span><span class="kw">lm</span>(a <span class="op">~</span><span class="st"> </span>X[,j])<span class="op">$</span>coef[<span class="dv">2</span>] <span class="co">#fit the jth dimension on the data and store the result</span>
  }
}
<span class="co">#plot the L2 errors for each iteration</span>
L2_errs&lt;-<span class="kw">sqrt</span>((<span class="kw">rowSums</span>(<span class="kw">sweep</span>(Bs,<span class="dv">2</span>,<span class="dt">STATS=</span>B)<span class="op">^</span><span class="dv">2</span>)))
<span class="kw">plot</span>(<span class="dv">1</span><span class="op">:</span>iters,L2_errs, <span class="dt">type=</span><span class="st">&quot;l&quot;</span>)</code></pre></div>
<p><img src="ISLR-exercises_files/figure-html/unnamed-chunk-205-1.png" width="672" /></p>

</div>
            </section>

          </div>
        </div>
      </div>
<a href="chap6.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="chap8.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"google": false,
"linkedin": false,
"weibo": false,
"instapper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"download": ["ISLR-exercises.pdf", "ISLR-exercises.epub"],
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "";
    if (src === "" || src === "true") src = "https://cdn.bootcss.com/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:" && /^https?:/.test(src))
      src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
